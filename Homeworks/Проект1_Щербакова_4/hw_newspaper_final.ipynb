{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import html\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# url начальной страницы газеты\n",
    "newspaper_url = 'http://polkrug.ru/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения ответа с сервера по запросу url_request\n",
    "def get_url_responce(url_request):\n",
    "    \n",
    "    # формируем запрос\n",
    "    req = urllib.request.Request(url_request)\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            # получаем ответ\n",
    "            html = response.read().decode('utf-8')\n",
    "            return html\n",
    "    \n",
    "    # если что-то пошло не так, возвращаем сообщение\n",
    "    except:\n",
    "        return 'URL RESPONSE ERROR!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения информации об авторе статьи\n",
    "def get_article_author(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска автора статьи\n",
    "    author_re = re.compile('</span><span class=\"author_fio\">(.*?)</span>')\n",
    "    # результат поиска\n",
    "    author_search = author_re.search(article_html)\n",
    "    \n",
    "    # если автор нашелся\n",
    "    if author_search:\n",
    "        # вернем его\n",
    "        return author_search.group(1)\n",
    "    \n",
    "    # иначе вернем 'no_author'\n",
    "    return 'no_author'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения названия статьи\n",
    "def get_article_title(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска названия статьи\n",
    "    title_re = re.compile('<h1>(.+)</h1>')\n",
    "    # результат поиска\n",
    "    title_search = title_re.search(article_html)\n",
    "    \n",
    "    # если заголовок нашелся\n",
    "    if title_search:\n",
    "        # вернем его\n",
    "        return title_search.group(1)\n",
    "    \n",
    "    # иначе вернем 'no_title'\n",
    "    return 'no_title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения даты статьи\n",
    "def get_article_date(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска даты статьи\n",
    "    date_re = re.compile('<div class=\"news_date\">(.+)</div>')\n",
    "    # результат поиска\n",
    "    date_search = date_re.search(article_html)\n",
    "    \n",
    "    # если дата не нашлась\n",
    "    if not date_search:\n",
    "        # вернем все это:\n",
    "        return 'no_day', 'no_month', 'no_year'\n",
    "    \n",
    "    # если дата указана, осталось перевести ее в нужный формат\n",
    "    date_split = date_search.group(1).split()\n",
    "    dd_str_raw, mm_str_raw, yy_str = date_split[0], date_split[1], date_split[2]\n",
    "    \n",
    "    # переводи дни месяца в нужный формат (1 -> 01)\n",
    "    if len(dd_str_raw) == 1:\n",
    "        dd_str = '0' + dd_str_raw\n",
    "    else:\n",
    "        dd_str = dd_str_raw\n",
    "    \n",
    "    # числовые значения месяцев года\n",
    "    month_dict = {'января': '01',\n",
    "                  'февраля': '02',\n",
    "                  'марта': '03',\n",
    "                  'апреля': '04',\n",
    "                  'мая': '05',\n",
    "                  'июня': '06',\n",
    "                  'июля': '07',\n",
    "                  'августа': '08',\n",
    "                  'сентября': '09',\n",
    "                  'октября': '10',\n",
    "                  'ноября': '11',\n",
    "                  'декабря': '12'}\n",
    "    \n",
    "    # переводим названия месяцев в числовые обозначения\n",
    "    mm_str = month_dict[mm_str_raw]\n",
    "    \n",
    "    return dd_str, mm_str, yy_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения категории и подкатегории (если есть) статьи\n",
    "def get_article_topic(article_html):\n",
    "    \n",
    "    # регулярные выражения для поиска категории и подкатегории\n",
    "    topic_re = re.compile('<div class=\"rubric_wrapper\">\\n\\s+<a class=\"rubric\" href=\"[^>]+\">([^<]+)</a>')\n",
    "    sub_topic_re = re.compile('<a class=\"podrubric\" href=\".+\">(.+)</a>')\n",
    "    \n",
    "    # результат поиска категории\n",
    "    topic_search = topic_re.search(article_html)\n",
    "    \n",
    "    # если категория указана, ОК\n",
    "    if topic_search:\n",
    "        topic = topic_search.group(1)\n",
    "    else:\n",
    "        # если нет, вернем вместо нее 'no topic'\n",
    "        topic = 'no_topic'\n",
    "    \n",
    "    # результат поиска подкатегории\n",
    "    sub_topic_search = sub_topic_re.search(article_html)\n",
    "    \n",
    "    # если нашли подкатегорию, добавим ее к категории через запятую и вернем это все\n",
    "    if sub_topic_search:\n",
    "        return topic + ', ' + sub_topic_search.group(1)\n",
    "    \n",
    "    # иначе вернем только категорию\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения текста статьи\n",
    "def get_article_text(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска текста статьи\n",
    "    text_re = re.compile('<p>.+?</p>|<h3>.+?</h3>', flags= re.DOTALL)\n",
    "    \n",
    "    # результат поиска\n",
    "    raw_text = text_re.findall(article_html)\n",
    "    \n",
    "    # список, в котором будут храниться абзацы текста\n",
    "    final_text = []\n",
    "    \n",
    "    # регулярное выражение для оставшихся тегов и проблельных символов\n",
    "    clean_re = re.compile('<.*?>|\\n|\\r|\\t')\n",
    "    \n",
    "    for paragraph in raw_text:\n",
    "        \n",
    "        # очищаем абзац от оставшихся тегов, проблеьных символов и переводим все специальные символы в обычные\n",
    "        clean_paragraph = html.unescape(clean_re.sub('', paragraph))\n",
    "    \n",
    "        # убираем строчку \"нет комментариев\", если она есть\n",
    "        if clean_paragraph == 'Нет комментариев':\n",
    "            continue\n",
    "        \n",
    "        # добавляем \"очищенный\" абзац к тексту\n",
    "        final_text.append(clean_paragraph)\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения ссылки на главное изображение статьи\n",
    "def get_main_image(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска главного изображения статьи\n",
    "    main_image_re = re.compile('class=\"main_img\" src=\"([^>]+)\"')\n",
    "    \n",
    "    # результат поиска\n",
    "    main_image_search = main_image_re.search(article_html)\n",
    "    \n",
    "    # если главное изображение нашлось, вернем его\n",
    "    if main_image_search:\n",
    "        return newspaper_url + main_image_search.group(1)\n",
    "    \n",
    "    # иначе вернем none\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения ссылок на изображения к статье\n",
    "def get_article_images(article_html):\n",
    "    \n",
    "    # регулярное выражение для поиска изображений к статье\n",
    "    image_re = re.compile('<a class=\"article_img\" target=\"_blank\" rel=\"gallery\" href=\"([^>]+)\">')\n",
    "    \n",
    "    # результат поиска\n",
    "    image_urls = image_re.findall(article_html)\n",
    "    \n",
    "    # список url изображений\n",
    "    image_urls_final = []\n",
    "    \n",
    "    # добавим url каждого изображения в список\n",
    "    for url in image_urls:\n",
    "        image_urls_final.append(newspaper_url + url)\n",
    "    \n",
    "    return image_urls_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения информации о статье и ее текста\n",
    "def get_article(article_url):\n",
    "    \n",
    "    # получаем html-файл со статьей\n",
    "    article_html = get_url_responce(newspaper_url + article_url)\n",
    "    \n",
    "    # заполняем словарь с информацией о статье\n",
    "    article_info = {'au': get_article_author(article_html),\n",
    "                    'ti': get_article_title(article_html),\n",
    "                    'da': get_article_date(article_html),\n",
    "                    'topic': get_article_topic(article_html),\n",
    "                    'url': newspaper_url + article_url,\n",
    "                    'main_img': get_main_image(article_html),\n",
    "                    'img': get_article_images(article_html)}\n",
    "    \n",
    "    # получаем текст статьи\n",
    "    article_text = get_article_text(article_html)\n",
    "    \n",
    "    return article_info, article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи чего-то, связанного со статьей, в файл\n",
    "def write_content(content, article_info, file_type):\n",
    "    \n",
    "    # словарь с расширениями\n",
    "    ext_dict = {'html': '.html',\n",
    "                'mystem-plain': '.txt'}\n",
    "    \n",
    "    # директория, в которую будет сохраняться файл\n",
    "    dirname = os.path.join('.', 'Газета', file_type, article_info['da'][2], article_info['da'][1])\n",
    "    \n",
    "    # если она не существует, создадим\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    \n",
    "    # имя файла = название статьи + нужное расширение\n",
    "    # полное имя файла для статьи = директория + имя файла\n",
    "    file_name = os.path.join(dirname, article_info['ti'] + ext_dict[file_type])\n",
    "    \n",
    "    # записываем в файл статью в режиме для чтения\n",
    "    with open(file_name, 'w', encoding='utf-8') as my_file:\n",
    "        my_file.write(content)\n",
    "    \n",
    "    # возвращаем полное имя файла - оно пригодится нам для mystem\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mystem_analysis(article_info, article_text):\n",
    "    \n",
    "    # имя директории для файла с резульатом mystem-palin\n",
    "    dirname_plain = os.path.join('.', 'Газета', 'mystem-plain', article_info['da'][2], article_info['da'][1])\n",
    "    \n",
    "    # если нужно, создаем ее\n",
    "    if not os.path.exists(dirname_plain):\n",
    "        os.makedirs(dirname_plain)\n",
    "    \n",
    "    # имя директории для файла с результатом mystem-xml\n",
    "    dirname_xml = os.path.join('.', 'Газета', 'mystem-xml', article_info['da'][2], article_info['da'][1])\n",
    "    \n",
    "    # если нужно, создаем ее\n",
    "    if not os.path.exists(dirname_xml):\n",
    "        os.makedirs(dirname_xml)\n",
    "    \n",
    "    # имя файла с результатом mystem-plain\n",
    "    filename_plain = os.path.join(dirname_plain, article_info['ti'].replace(' ', '_') + '.txt')\n",
    "    \n",
    "    # имя файла с результатом mystem-xml\n",
    "    filename_xml = os.path.join(dirname_xml, article_info['ti'].replace(' ', '_') + '.xml')\n",
    "    \n",
    "    # записываем текст статьи во временный файл\n",
    "    with open('buffer.txt', 'w', encoding='utf-8') as my_file:\n",
    "        my_file.write(' '.join(article_text))\n",
    "    \n",
    "    # вызываем mystem для plain\n",
    "    os.system('./mystem -cdinl --eng-gr buffer.txt ' + filename_plain)\n",
    "    \n",
    "    # вызываем mystem для xml\n",
    "    os.system('./mystem -cdinl --eng-gr --format xml buffer.txt ' + filename_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distilled_html(article_info, article_text):\n",
    "    \n",
    "    # открываем html заготовку, из которой будем делать статью в режиме для чтения\n",
    "    with open('template.html', 'r', encoding='utf-8') as source_file:\n",
    "        html_template = source_file.read()\n",
    "    \n",
    "    # заменяем ее части на то, что нужно\n",
    "    html_template = html_template.replace('article_title', article_info['ti'])\n",
    "    html_template = html_template.replace('author_name', article_info['au'])\n",
    "    html_template = html_template.replace('article_date', '.'.join(article_info['da']))\n",
    "    html_template = html_template.replace('article_url', article_info['url'])\n",
    "    html_template = html_template.replace('article_topic', article_info['topic'])\n",
    "    html_template = html_template.replace('article_url', article_info['url'])\n",
    "    \n",
    "    # будущий текст html-файла для чтения\n",
    "    text_html = ''\n",
    "    \n",
    "    # вставляем главное изображение, если есть\n",
    "    if article_info['main_img']:\n",
    "        text_html += '<center><img src=\"' + article_info['main_img'] +  '\"></center>'\n",
    "    \n",
    "    # собираем из параграфов текст и вставляем его\n",
    "    for paragraph in article_text:\n",
    "        text_html += '<p>' + paragraph + '</p>'\n",
    "    \n",
    "    html_template = html_template.replace('article_text', text_html)\n",
    "    \n",
    "    # часть html-файла, в которой будут картинки\n",
    "    images_html = ''\n",
    "    \n",
    "    # дописываем \"Фото к статье:\", если есть картинки\n",
    "    if len(article_info['img']) > 0:\n",
    "        images_html += '<br/>Фото к статье:<br/><br/>'\n",
    "    \n",
    "    # вставляем картинки к статье, если есть\n",
    "    for image in article_info['img']:\n",
    "        images_html += '<center><img src=\"' + image + '\"></center><br/><br/>'\n",
    "    html_template = html_template.replace('image_block', images_html)\n",
    "    \n",
    "    # записываем получившийся html-файл куда нужно \n",
    "    write_content(html_template, article_info, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_line(article_info):\n",
    "    \n",
    "    # строчка для мета-таблицы\n",
    "    row = '%s\\t%s\\t\\t\\t%s\\t%s\\tпублицистика\\t\\t\\t%s\\t\\tнейтральный\\tн-возраст\\tн-уровень\\t' +\\\n",
    "        'городская\\t%s\\t\"Полярный круг\"\\t\\t%s\\tгазета\\tРоссия\\tЯНАО\\tru'\n",
    "    \n",
    "    # заполним ее!\n",
    "    metadata_line = row % (article_info['url'], article_info['au'], article_info['ti'], '.'.join(article_info['da']),\n",
    "                           article_info['topic'], article_info['url'], article_info['da'][2])\n",
    "    \n",
    "    # мы считаем, что \"path -- это путь к чистому неразмеченному файлу со статьёй\" - это url страницы\n",
    "    # иначе нужно было бы создавать отдельную папку с неразмеченным текстом на комрьютере,\n",
    "    # а этого нет в структуре каталогов в описании проекта\n",
    "    \n",
    "    # и вернем\n",
    "    return metadata_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета количества слов в тексте\n",
    "def get_text_word_count(article_text):\n",
    "    \n",
    "    # счетчик слов\n",
    "    word_cnt = 0\n",
    "    \n",
    "    # для каждого абзаца в тексте\n",
    "    for paragraph in article_text:\n",
    "        # добавляем его количество слов к счетчику слов\n",
    "        word_cnt += len(paragraph.split())\n",
    "    \n",
    "    return word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для сохранения страницы с режимом для чтения, вызова mystem и сохранения размеченного текста в формате XML\n",
    "def handle_article_page(article_info, article_text):\n",
    "    \n",
    "    # посчитаем, сколько слов содержит статья\n",
    "    word_cnt = get_text_word_count(article_text)\n",
    "    \n",
    "    # создадим html-файл со статьей в режиме для чтения\n",
    "    make_distilled_html(article_info, article_text)\n",
    "    \n",
    "    # произведем анализ mystem'ом\n",
    "    make_mystem_analysis(article_info, article_text)\n",
    "    \n",
    "    # получим строчку мета-таблицы\n",
    "    metadata_line = get_metadata_line(article_info)\n",
    "    \n",
    "    return metadata_line, word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения url следующей статьи газеты\n",
    "def get_next_page_url(now_page_url):\n",
    "    \n",
    "    # получим html-файл текущей страницы\n",
    "    now_html = get_url_responce(newspaper_url + now_page_url)\n",
    "    \n",
    "    # регулярное выражение для поиска ссылки на следующую страницу\n",
    "    next_re = re.compile('<li class=\"next\"><a href=\"([^\"]+)\">')\n",
    "    \n",
    "    # результат поиска\n",
    "    next_page_url_search = next_re.search(now_html)\n",
    "    \n",
    "    # если следующая страница нашлась, вернем ее url\n",
    "    if next_page_url_search:\n",
    "        return next_page_url_search.group(1)\n",
    "    \n",
    "    # иначе вернем None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения url статей на странице\n",
    "def get_page_articles(page_url):\n",
    "    \n",
    "    # получим html-файл текущей страницы\n",
    "    page_html = get_url_responce(newspaper_url + page_url)\n",
    "    \n",
    "    # регулярное выражение для поиска ссылок на статьи\n",
    "    article_re = re.compile('<h3>\\s*<a href=\"([^\"]+)\">')\n",
    "    \n",
    "    # результат поиска\n",
    "    articles = article_re.findall(page_html)\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# главная функция - она начинает со страницы start_url, ищет на ней статьи, обрабатывает их,\n",
    "# а потом делает то же самое для остальных страниц\n",
    "def load_newspaper_articles(start_url):\n",
    "    \n",
    "    # начинаем с первой страницы\n",
    "    now_page_url = start_url\n",
    "    \n",
    "    # счетчик слов обработанных статей\n",
    "    total_word_cnt = 0\n",
    "    \n",
    "    # список строчек мета-таблицы\n",
    "    metadata_list = []\n",
    "    \n",
    "    # пока страницы газеты в нужной рубрике не закончились, выкачиваем с них статьи и обрабатываем их\n",
    "    while now_page_url:\n",
    "        \n",
    "        # сотрем то, что было до этого в выводе\n",
    "        clear_output()\n",
    "        \n",
    "        # печатаем url текущей страницы газеты, чтобы видеть, что программа жива\n",
    "        print(now_page_url)\n",
    "        \n",
    "        # получаем url статей текущей страницы\n",
    "        now_page_article_urls = get_page_articles(now_page_url)  \n",
    "        \n",
    "        # для каждой статьи из списка\n",
    "        for article_url in now_page_article_urls:\n",
    "            \n",
    "            # обрабатываем ee и получаем строчки мета-таблицы\n",
    "            metadata_line, word_cnt = handle_article_page(*get_article(article_url))\n",
    "            \n",
    "            # записываем строку в мета-таблицу\n",
    "            metadata_list.append(metadata_line)\n",
    "            \n",
    "            # добавляем количество слов статьи к полному количеству слов\n",
    "            total_word_cnt += word_cnt\n",
    "        \n",
    "        # получаем url следующей страницы газеты\n",
    "        now_page_url = get_next_page_url(now_page_url)\n",
    "        \n",
    "    # записываем мета-таблицу в файл\n",
    "    with open(os.path.join('.', 'Газета', 'metadata.csv'), 'w', encoding='utf-8') as metadata_file:\n",
    "        metadata_file.write('\\n'.join(metadata_list))\n",
    "    \n",
    "    # печатаем, сколько слов обработали\n",
    "    print('Суммарный объем статей: ' + str(total_word_cnt) + ' слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/news/kultura?p=72\n",
      "Суммарный объем статей: 325655 слов\n"
     ]
    }
   ],
   "source": [
    "# вызываем главную функцию от раздела \"Культура\" газеты \"Полярный круг\"\n",
    "load_newspaper_articles('news/kultura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
